{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "HW4_Sentiment Analysis_using_RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol9wi-RNxtj1"
      },
      "source": [
        "# Sentiment Analysis using RNNs\n",
        "\n",
        "Please download this notebook onto your Google Drive. \n",
        "Insert your name and ISU ID Number here in the usual form:\n",
        "SONG, SeokHwan   | 701520820"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbX2_UlNG7gC"
      },
      "source": [
        "## 1 - Sentiment Analysis Overview\n",
        "\n",
        "In this series we'll be building a machine learning model to detect sentiment (i.e. detect if a sentence is positive or negative) using PyTorch and TorchText. This will be done on movie reviews, using the IMDb dataset.\n",
        "We'll start very simple to understand the general concepts and further notebooks will build on this knowledge to actually get good results.\n",
        "\n",
        "**Introduction**\n",
        "We'll start out with a recurrent neural network (RNN) as they are commonly used in analysing sequences. An RNN takes in sequence of words,  ùëã=${ùë•_1,...,ùë•_ùëá} $, one at a time, and produces a hidden state,  ‚Ñé , for each word. We use the RNN recurrently by feeding in the current word $x_t$ as well as the hidden state from the previous word,  $‚Ñé_{ùë°‚àí1}$ , to produce the next hidden state, $h_t$.\n",
        "\n",
        "$h_t=RNN(x_t,‚Ñé_{ùë°‚àí1})$\n",
        "\n",
        "Once we have our final hidden state,  $h_t$ , (from feeding in the last word in the sequence,$x_T$) we feed it through a linear layer, ùëì , (also known as a fully connected layer), to receive our predicted sentiment,  ùë¶ÃÇ=ùëì($‚Ñé_ùëá$) .\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment1.png?raw=1)\n",
        "\n",
        "Note: some layers and steps have been omitted from the diagram, but these will be explained later.\n",
        "\n",
        "We will compare the effects of different changes to the system:\n",
        "\n",
        "\n",
        "**Homework Outline:**\n",
        "1. Standard RNN\n",
        "2. Standard RNN with pre-trained word embeddings\n",
        "3. RNN with LSTM blocks \n",
        "4. LSTM with regularization\n",
        "5. Bidirectional RNN with regularization\n",
        "6. Multi-layer RNN with regularization\n",
        "\n",
        "This will allow us to achieve ~84% test accuracy.\n",
        "\n",
        "This lab is based on very clearly written and explained examples from Ben Trevett of Heriot-Watt University in Scotland. https://github.com/bentrevett/pytorch-sentiment-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T2LqBp0G7gF"
      },
      "source": [
        "##2. Preparing Data\n",
        "\n",
        "One of the main concepts of TorchText is the Field. The parameters of a Field specify how the data should be processed. In our sentiment classification task the data consists of both the raw string of the review and the sentiment, either \"pos\" or \"neg\".\n",
        "\n",
        "We use the TEXT field to define how the review should be processed, and the LABEL field to process the sentiment. We'll be using *packed padded sequences*, which will make our RNN only process the non-padded elements of our sequence, and for any padded element the output will be a zero tensor. To use packed padded sequences, we have to tell the RNN how long the actual sequences are. We do this by setting include_lengths = True for our TEXT field. This will cause batch.text to now be a tuple with the first element being our sentence (a numericalized tensor that has been padded) and the second element being the actual lengths of our sentences.\n",
        "\n",
        "Our TEXT field has tokenize='spacy' as an argument. This defines that the \"tokenization\" (the act of splitting the string into discrete \"tokens\") should be done using the [spaCy](https://spacy.io) tokenizer. If no tokenize argument is passed, the default is simply splitting the string on spaces.\n",
        "\n",
        "LABEL is defined by a LabelField, a special subset of the Field class specifically used for handling labels. We will explain the dtype argument later.\n",
        "For more on Fields, go [here](https://github.com/pytorch/text/blob/master/torchtext/data/field.py).\n",
        "\n",
        "We also set the random seeds for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2X43bU-G7gH"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLEloPeEG7gQ"
      },
      "source": [
        "A handy feature of TorchText is that it has support for common datasets used in natural language processing (NLP). The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as torchtext.datasets objects. It processes the data using the Fields we have previously defined. The IMDb dataset consists of 50,000 movie reviews, each marked as being a positive or negative review.\n",
        "\n",
        "The IMDb dataset only has train/test splits, so we need to create a validation set. We can do this with the .split() method. By default this splits 70/30, however by passing a split_ratio argument, we can change the ratio of the split, i.e. a split_ratio of 0.8 would mean 80% of the examples make up the training set and 20% make up the validation set.\n",
        "\n",
        "We also pass our random seed to the random_state argument, ensuring that we get the same train/validation split each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AKjofWuG7gS",
        "outputId": "a7db546e-9c7f-4825-86b0-1954f5c4a5bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchtext import datasets\n",
        "import random\n",
        "\n",
        "train_data_in, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data_in.split(random_state = random.seed(SEED),split_ratio= .80)\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84.1M/84.1M [00:05<00:00, 15.9MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of testing examples: 25000\n",
            "{'text': ['The', 'opening', 'sequence', 'is', 'supposed', 'to', 'show', 'the', 'Legion', 'arriving', 'in', 'Paris', 'on', '13', 'Nov', '1918', '.', 'The', 'troops', 'pile', 'off', 'the', 'train', '--', 'wearing', 'the', 'uniform', 'in', 'which', 'the', 'French', 'Army', ',', 'including', 'the', 'Legion', ',', 'marched', 'off', 'to', 'war', 'in', '1914', '!', 'This', 'a', 'sure', 'sign', 'that', 'the', 'war', 'flick', 'you', 'are', 'about', 'to', 'see', 'will', 'be', 'a', 'turkey', '.', '(', 'The', 'French', 'Army', 'realized', 'by', '1915', 'that', 'going', 'to', 'war', 'in', 'red', 'trousers', 'and', 'dark', 'blue', 'overcoats', 'was', 'not', 'working', '.', 'Metropolitan', 'French', 'troops', 'were', 'put', 'into', '\"', 'horizon', 'blue', '\"', 'and', 'Colonial', 'troops', 'were', 'put', 'into', 'khaki', '.', ')', 'The', 'Claude', 'Van', '-', 'Damme', '(', 'sp', '?', ')', 'remake', 'at', 'least', 'got', 'the', 'uniforms', 'more', 'or', 'less', 'right', '.', 'Really', 'is', 'too', 'bad', 'when', 'directors', 'make', 'these', 'sorts', 'of', 'mistakes', 'when', 'they', 'then', 'go', 'to', 'all', 'the', 'effort', 'to', 'get', 'other', 'things', 'right', '.'], 'label': 'neg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJSuPld_1sn7"
      },
      "source": [
        "##3 Building a Vocabulary and Bringing in an Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY4BRQ9n0aJ1"
      },
      "source": [
        "###3.1 Vocabulary\n",
        "Next, we have to build a _vocabulary_. This is a effectively a look up table where every unique word in your data set has a corresponding _index_ (an integer). A one-hot vector is a vector where all of the elements are 0, except one, which is 1, and dimensionality is the total number of unique words in your vocabulary, commonly denoted by $V$.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment5.png?raw=1)\n",
        "\n",
        "The number of unique words in our training set is over 100,000, which means that our one-hot vectors will have over 100,000 dimensions! This will make training slow and possibly won't fit onto your GPU (if you're using one). There are two ways effectively cut down our vocabulary, we can either only take the top $n$ most common words or ignore words that appear less than $m$ times. We'll do the former, only keeping the top 25,000 words.\n",
        "\n",
        "Words that appear in examples but we have cut from the vocabulary are replaced with a `<unk>` token. The following builds the vocabulary, only keeping the most common `max_size` tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqaLmVJFG7gc"
      },
      "source": [
        "###3.2 Pre-Trained Word Embeddings\n",
        "Next is the use of pre-trained word embeddings. Now, instead of having our word embeddings initialized randomly, they are initialized with pre-trained vectors.\n",
        "We get these vectors simply by specifying which vectors we want and passing it as an argument to `build_vocab`. `TorchText` handles downloading the vectors and associating them with the correct words in our vocabulary.\n",
        "\n",
        "Here, we'll be using the `\"glove.6B.100d\" vectors\"`. `glove` is the algorithm used to calculate the vectors, go [here](https://nlp.stanford.edu/projects/glove/) for more. `6B` indicates these vectors were trained on 6 billion tokens and `100d` indicates these vectors are 100-dimensional.\n",
        "\n",
        "You can see the other available embeddings [here](https://github.com/pytorch/text/blob/master/torchtext/vocab.py#L113).\n",
        "\n",
        "The theory is that these pre-trained vectors already have words with similar semantic meaning close together in vector space, e.g. \"terrible\", \"awful\", \"dreadful\" are nearby. This gives our embedding layer a good initialization as it does not have to learn these relations from scratch.\n",
        "\n",
        "**Note**: these vectors are about 862MB, so watch out if you have a limited internet connection.\n",
        "\n",
        "By default, TorchText will initialize words in your vocabulary but not in your pre-trained embeddings to zero. We don't want this, and instead initialize them randomly by setting `unk_init` to `torch.Tensor.normal_`. This will now initialize those words via a Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmNsuXSwG7gd",
        "outputId": "e0932ca3-eef5-4bec-8324-226b83685dad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:29, 2.21MB/s]                          \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 398788/400000 [00:15<00:00, 26312.82it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBp97YZ-ranq",
        "outputId": "b95b0e89-18e0-41d4-c866-7b22b3608404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "print(TEXT.vocab.itos[:50])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is', 'in', 'I', 'it', 'that', '\"', \"'s\", 'this', '-', '/><br', 'was', 'as', 'movie', 'with', 'for', 'film', 'The', 'but', '(', ')', \"n't\", 'on', 'you', 'are', 'not', 'have', 'his', 'be', 'he', 'one', 'at', '!', 'by', 'all', 'an', 'who', 'they', 'from', 'like', 'so', 'her']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGph6shfG7gi"
      },
      "source": [
        "###3.3 Creating the Iterators\n",
        "\n",
        "The final step of preparing the data is creating the iterators. We iterate over these in the training/evaluation loop, and they return a batch of examples (indexed and converted into tensors) at each iteration. We'll use a BucketIterator which is a special type of iterator that will return a batch of examples where each example is of a similar length, minimizing the amount of padding per example.\n",
        "\n",
        "We also want to place the tensors returned by the iterator on the GPU (if you're using one). PyTorch handles this using torch.device, we then pass this device to the iterator. For packed padded sequences all of the tensors within a batch need to be sorted by their lengths. This is handled in the iterator by setting `sort_within_batch = True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLd06NsSG7gi"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp3mCqMr9FYc"
      },
      "source": [
        "##4 Build the Model\n",
        "\n",
        "The model will be based on different RNN structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j57UeuHo9fnx"
      },
      "source": [
        "###4.1 Vanilla RNN Architecture\n",
        "The three layers of the Vanilla RNN are an _embedding_ layer, our RNN, and a _linear_ layer. All layers have their parameters initialized to random values, unless explicitly specified.\n",
        "\n",
        "The embedding layer is used to transform our sparse one-hot vector (sparse as most of the elements are 0) into a dense embedding vector (dense as the dimensionality is a lot smaller and all the elements are real numbers). This embedding layer is simply a single fully connected layer. As well as reducing the dimensionality of the input to the RNN, there is the theory that words which have similar impact on the sentiment of the review are mapped close together in this dense vector space. The RNN layer is our RNN which takes in our dense vector and the previous hidden state $h_{t-1}$, which it uses to calculate the next hidden state, $h_t$. Finally, the linear layer takes the final hidden state and feeds it through a fully connected layer, $f(h_T)$, transforming it to the correct output dimension.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment7.png?raw=1)\n",
        "\n",
        "The `forward` method is called when we feed examples into our model.\n",
        "\n",
        "Each batch, `text`, is a tensor of size _**[sentence length, batch size]**_. That is a batch of sentences, each having each word converted into a one-hot vector. \n",
        "\n",
        "You may notice that this tensor should have another dimension due to the one-hot vectors, however PyTorch conveniently stores a one-hot vector as it's index value, i.e. the tensor representing a sentence is just a tensor of the indexes for each token in that sentence. The act of converting a list of tokens into a list of indexes is commonly called *numericalizing*.\n",
        "\n",
        "The input batch is then passed through the embedding layer to get `embedded`, which gives us a dense vector representation of our sentences. `embedded` is a tensor of size _**[sentence length, batch size, embedding dim]**_. `embedded` is then fed into the RNN. In some frameworks you must feed the initial hidden state, $h_0$, into the RNN, however in PyTorch, if no initial hidden state is passed as an argument it defaults to a tensor of all zeros.\n",
        "\n",
        "The RNN returns 2 tensors, `output` of size _**[sentence length, batch size, hidden dim]**_ and `hidden` of size _**[1, batch size, hidden dim]**_. `output` is the concatenation of the hidden state from every time step, whereas `hidden` is simply the final hidden state. We verify this using the `assert` statement. Note the `squeeze` method, which is used to remove a dimension of size 1. \n",
        "\n",
        "Finally, we feed the last hidden state, `hidden`, through the linear layer, `fc`, to produce a prediction.\n",
        "\n",
        "**Note:** To use an LSTM instead of the standard RNN, we use `nn.LSTM` instead of `nn.RNN`. Also, note that the LSTM returns the `output` and a tuple of the final `hidden` state and the final `cell` state, whereas the standard RNN only returned the `output` and final `hidden` state. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcYjd8zjU-Uz"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Vanilla_RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        # LSTM layer\n",
        "        #self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "\n",
        "        # Output for LSTM\n",
        "        #output, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVZx6HxVV0pf"
      },
      "source": [
        "We now create an instance of our VanillaRNN class.\n",
        "The input dimension is the dimension of the one-hot vectors, which is equal to the vocabulary size. The embedding dimension is the size of the dense word vectors. This is usually around 50-250 dimensions, but depends on the size of the vocabulary.\n",
        "The hidden dimension is the size of the hidden states. This is usually around 100-500 dimensions, but also depends on factors such as on the vocabulary size, the size of the dense vectors and the complexity of the task.\n",
        "The output dimension is usually the number of classes, however in the case of only 2 classes the output value is between 0 and 1 and thus can be 1-dimensional, i.e. a single scalar real number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkWQ9sDDVsyT"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = Vanilla_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJq1365Ri4D9"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb_6hWtcwnwR"
      },
      "source": [
        "The final piece is copying the pre-trained word embeddings we loaded earlier into the embedding layer of our model. We retrieve the embeddings from the field's vocab, and check they're the correct size, [vocab size, embedding dim].\n",
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings. **Note: this should always be done on the weight.data and not the weight!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIVFLaltwFgL",
        "outputId": "09bc9d44-1322-48ca-b8cf-05d500a96062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.7922, -0.1901, -0.0676,  ...,  1.0146,  0.2398,  0.0675],\n",
              "        [ 0.4161, -0.1577, -0.0735,  ...,  0.3023,  0.2679,  0.6584],\n",
              "        [ 0.9501, -0.7701,  0.1537,  ..., -2.0229,  0.4822, -1.0561]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJoQ2bBAweSj"
      },
      "source": [
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings.\n",
        "Note: this should always be done on the weight.data and not the weight!\n",
        "We can now see the first two rows of the embedding weights matrix have been set to zeros. As we passed the index of the pad token to the padding_idx of the embedding layer it will remain zeros throughout training, however the <unk> token embedding will be learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "resYOuu_wYxv",
        "outputId": "1f04057f-945b-49e1-d5fb-ca55ed5da056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.7922, -0.1901, -0.0676,  ...,  1.0146,  0.2398,  0.0675],\n",
            "        [ 0.4161, -0.1577, -0.0735,  ...,  0.3023,  0.2679,  0.6584],\n",
            "        [ 0.9501, -0.7701,  0.1537,  ..., -2.0229,  0.4822, -1.0561]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_DqL8dvZB8o"
      },
      "source": [
        "###4.2 Utility Routines for running the models\n",
        "*count_parameters* a function that will tell us how many trainable parameters our model has so we can compare the number of parameters across different models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk-XbJNtZKaP",
        "outputId": "49406820-e27a-4edc-cf92-2f76db098e63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aByyYH4ZZfmQ"
      },
      "source": [
        "*binary_accuracy* calculate the accuracy of the sentiment analysis. It first feeds the predictions through a sigmoid layer, squashing the values between 0 and 1, we then round them to the nearest integer. \n",
        "We then calculate how many rounded predictions equal the actual labels and average it across the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF4WMJsqZfAc"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oohty6HkaRsv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-NfClObbx4z"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        text, text_lengths = batch.text\n",
        "                \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        " "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r4aDGC6ahzx"
      },
      "source": [
        "*evaluate* is similar to train, with a few modifications to avoid updating the parameters when evaluating.\n",
        "model.eval() puts the model in \"evaluation mode\", this turns off dropout and batch normalization. Again, we are not using them in this model, but it is good practice to include them.\n",
        "No gradients are calculated on PyTorch operations inside the with no_grad() block. This causes less memory to be used and speeds up computation.\n",
        "The rest of the function is the same as train, with the removal of optimizer.zero_grad(), loss.backward() and optimizer.step(), as we do not update the model's parameters when evaluating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVaWo6h3afM8"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79D8dSqaa-0H"
      },
      "source": [
        "*epoch_time* is a function to tell us how long an epoch takes to compare training times between models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PssE-gGYbL49"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4eBzHSbbdte"
      },
      "source": [
        "###4.3 Training the Model\n",
        "We then train the model through multiple epochs, an epoch being a complete pass through all examples in the training and validation sets.\n",
        "At each epoch, if the validation loss is the best we have seen so far, we'll save the parameters of the model and then after training has finished we'll use that model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3bRiweNbYJo",
        "outputId": "9804fcdb-8182-4575-e3a0-3ce5d398f467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 398788/400000 [00:29<00:00, 26312.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.52%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 51.92%\n",
            "Epoch: 02 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.68%\n",
            "\t Val. Loss: 0.711 |  Val. Acc: 50.63%\n",
            "Epoch: 03 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.694 | Train Acc: 51.59%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 53.68%\n",
            "Epoch: 04 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.692 | Train Acc: 52.36%\n",
            "\t Val. Loss: 0.678 |  Val. Acc: 57.46%\n",
            "Epoch: 05 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.690 | Train Acc: 52.46%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 50.45%\n",
            "Epoch: 06 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.694 | Train Acc: 51.29%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 51.13%\n",
            "Epoch: 07 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.689 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 54.41%\n",
            "Epoch: 08 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.675 | Train Acc: 57.65%\n",
            "\t Val. Loss: 0.720 |  Val. Acc: 50.65%\n",
            "Epoch: 09 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.677 | Train Acc: 55.37%\n",
            "\t Val. Loss: 0.768 |  Val. Acc: 54.75%\n",
            "Epoch: 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.673 | Train Acc: 56.69%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 51.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJHsaiPb0hqL"
      },
      "source": [
        "###4.4 Testing the Model\n",
        "You may have noticed the loss is not uniformly decreasing and the accuracy is around 70%. This is due to several issues with the model which we'll improve in the next part.\n",
        "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaTt_lkH0gY5",
        "outputId": "0e82a055-fa26-4f61-a791-97e7c4754053",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.665 | Test Acc: 59.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLGleSIn1KRN"
      },
      "source": [
        "This section provides a function to put in your own movie review quotes to predict the sentiment of any sentence we give it. As it has been trained on movie reviews, the sentences provided should also be movie reviews.\n",
        "\n",
        "When using a model for inference it should always be in evaluation mode. If this tutorial is followed step-by-step then it should already be in evaluation mode (from doing `evaluate` on the test set), however we explicitly set it to avoid any risk.\n",
        "\n",
        "Our `predict_sentiment` function does a few things:\n",
        "- sets the model to evaluation mode\n",
        "- tokenizes the sentence, i.e. splits it from a raw string into a list of tokens\n",
        "- indexes the tokens by converting them into their integer representation from our vocabulary\n",
        "- gets the length of our sequence\n",
        "- converts the indexes, which are a Python list into a PyTorch tensor\n",
        "- add a batch dimension by `unsqueeze`ing \n",
        "- converts the length into a tensor\n",
        "- squashes the output prediction from a real number between 0 and 1 with the `sigmoid` function\n",
        "- converts the tensor holding a single value into an integer with the `item()` method\n",
        "\n",
        "We are expecting reviews with a negative sentiment to return a value close to 0 and positive reviews to return a value close to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKQ7YHVg0f6v"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv2aaYOR177d"
      },
      "source": [
        "Sample Reviews from Rotten Tomatoes for Inception and the Angry Birds 2 Movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXhdEWhC2JK3"
      },
      "source": [
        "Negative Reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2RA5lsu2Nw-",
        "outputId": "f6c81330-1766-41f2-d664-d730d7498b31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "predict_sentiment(model, \"I will pretend I loved it and worship it like all the the smartest people and didn't get kinda lost half way and stopped watching like 40 minutes before the end cause I was utterly uninterested in how it would end.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.541588306427002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlKBahE82TuS",
        "outputId": "e2462a81-3b68-4894-c626-61d4e8657382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"Children will sit through it happily enough, but they deserve better, don't they?\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5679482221603394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w6h7PN_2Yhj"
      },
      "source": [
        "Medium Reviews: (ratings 3 and 3.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfgcSef72f2L",
        "outputId": "5cdd1516-e3be-40b5-d305-96293cc6353c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model,\"Invention runs lower once we're on those snowy slopes, and the hard narrative punch keeps disintegrating into a floating cloud of pixels.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5012223124504089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vwv0lP_2mRL",
        "outputId": "e09eaed8-dec4-4e02-948a-8d875397b12a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"The idea of the show, and the acting are amazing, but even as a lover of violence, some of the scenes involving animals and even some scenes involving people just felt.... baseless\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5329797863960266"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRj_I3o82yvA"
      },
      "source": [
        "Positive Reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2PHoIry2w6v",
        "outputId": "4758c000-a733-4b65-a144-9f87144f8ff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"A spectacular fantasy thriller based on Nolan's own original screenplay, Inception is the smartest CGI head-trip since The Matrix.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5802634954452515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z7cszi2G7gl"
      },
      "source": [
        "\n",
        "##5 Different RNN Architectures\n",
        "\n",
        "We will now use an RNN based on Long Short-Term Memory (LSTM) modules. Recall, standard RNNs suffer from the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). LSTMs overcome this by having an extra recurrent state called a _cell_, $c$ - which can be thought of as the \"memory\" of the LSTM - and the use use multiple _gates_ which control the flow of information into and out of the memory. \n",
        "\n",
        "Thus, the model using an LSTM looks something like (with the embedding layers omitted):\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment2.png?raw=1)\n",
        "\n",
        "The initial cell state, $c_0$, like the initial hidden state is initialized to a tensor of all zeros. The sentiment prediction is still, however, only made using the final hidden state, not the final cell state, i.e. $\\hat{y}=f(h_T)$.\n",
        "\n",
        "### Bidirectional RNN\n",
        "\n",
        "A bidirectional RNN is an RNN processing the words in the sentence from the first to the last (a forward RNN) with a second RNN processing the words in the sentence from the **last to the first** (a backward RNN). At time step $t$, the forward RNN is processing word $x_t$, and the backward RNN is processing word $x_{T-t+1}$. \n",
        "\n",
        "In PyTorch, the hidden state (and cell state) tensors returned by the forward and backward RNNs are stacked on top of each other in a single tensor. \n",
        "\n",
        "We make our sentiment prediction using a concatenation of the last hidden state from the forward RNN (obtained from final word of the sentence), $h_T^\\rightarrow$, and the last hidden state from the backward RNN (obtained from the first word of the sentence), $h_T^\\leftarrow$, i.e. $\\hat{y}=f(h_T^\\rightarrow, h_T^\\leftarrow)$   \n",
        "\n",
        "The image below shows a bi-directional RNN, with the forward RNN in orange, the backward RNN in green and the linear layer in silver.  \n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment3.png?raw=1)\n",
        "\n",
        "### Multi-layer RNN\n",
        "\n",
        "Multi-layer RNNs (also called *deep RNNs*) are another simple concept. The idea is that we add additional RNNs on top of the initial standard RNN, where each RNN added is another *layer*. The hidden state output by the first (bottom) RNN at time-step $t$ will be the input to the RNN above it at time step $t$. The prediction is then made from the final hidden state of the final (highest) layer.\n",
        "\n",
        "The image below shows a multi-layer unidirectional RNN, where the layer number is given as a superscript. Also note that each layer needs their own initial hidden state, $h_0^L$.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment4.png?raw=1)\n",
        "\n",
        "### Regularization\n",
        "\n",
        "Although we've added improvements to our model, each one adds additional parameters. The more parameters you have in in your model, the higher the probability that your model will overfit (memorize the training data, causing  a low training error but high validation/testing error, i.e. poor generalization to new, unseen examples). To combat this, we use  a method of regularization called *dropout*. Dropout works by randomly *dropping out* (setting to 0) neurons in a layer during a forward pass. The probability that each neuron is dropped out is set by a hyperparameter and each neuron with dropout applied is considered indepenently. One theory about why dropout works is that a model with parameters dropped out can be seen as a \"weaker\" (less parameters) model. The predictions from all these \"weaker\" models (one for each forward pass) get averaged together withinin the parameters of the model. Thus, your one model can be thought of as an ensemble of weaker models, none of which are over-parameterized and thus should not overfit.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B6EZnrG6JL9"
      },
      "source": [
        "*Ïù¥ÌÉ§Î¶≠Ï≤¥ ÌÖçÏä§Ìä∏*###5.1 Implementation Details\n",
        "\n",
        "To use an LSTM instead of the standard RNN, we use `nn.LSTM` instead of `nn.RNN`. Also, note that the LSTM returns the `output` and a tuple of the final `hidden` state and the final `cell` state, whereas the standard RNN only returned the `output` and final `hidden` state. \n",
        "\n",
        "As the final hidden state of our LSTM has both a forward and a backward component, which will be concatenated together, the size of the input to the `nn.Linear` layer is twice that of the hidden dimension size.\n",
        "\n",
        "Implementing bidirectionality and adding additional layers are done by passing values for the `num_layers` and `bidirectional` arguments for the RNN/LSTM. \n",
        "\n",
        "Dropout is implemented by initializing an `nn.Dropout` layer (the argument is the probability of dropping out each neuron) and using it within the `forward` method after each layer we want to apply dropout to. **Note**: never use dropout on the input or output layers (`text` or `fc` in this case), you only ever want to use dropout on intermediate layers. The LSTM has a `dropout` argument which adds dropout on the connections between hidden states in one layer to hidden states in the next layer. Thus, dropout will not work for a single layer LSTM.\n",
        "\n",
        "Before we pass our embeddings to the RNN, we need to pack them, which we do with `nn.utils.rnn.packed_padded_sequence`. This will cause our RNN to only process the non-padded elements of our sequence. The RNN will then return `packed_output` (a packed sequence) as well as the `hidden` and `cell` states (both of which are tensors). Without packed padded sequences, `hidden` and `cell` are tensors from the last element in the sequence, which will most probably be a pad token, however when using packed padded sequences they are both from the last non-padded element in the sequence. \n",
        "\n",
        "We then unpack the output sequence, with `nn.utils.rnn.pad_packed_sequence`, to transform it from a packed sequence to a tensor. The elements of `output` from padding tokens will be zero tensors (tensors where every element is zero). Usually, we only have to unpack output if we are going to use it later on in the model. Although we aren't in this case, we still unpack the sequence just to show how it is done.\n",
        "\n",
        "The final hidden state, `hidden`, has a shape of _**[num layers * num directions, batch size, hid dim]**_. These are ordered: **[forward_layer_0, backward_layer_0, forward_layer_1, backward_layer 1, ..., forward_layer_n, backward_layer n]**. As we want the final (top) layer forward and backward hidden states, we get the top two hidden layers from the first dimension, `hidden[-2,:,:]` and `hidden[-1,:,:]`, and concatenate them together before passing them to the linear layer (after applying dropout). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lNv_BOLG7gm"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "         \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZVqUGPG7go"
      },
      "source": [
        "Like before, we'll create an instance of our RNN class, with the new parameters and arguments for the number of layers, bidirectionality and dropout probability.  To ensure the pre-trained vectors can be loaded into the model, the `EMBEDDING_DIM` must be equal to that of the pre-trained GloVe vectors loaded earlier.\n",
        "\n",
        "We get our pad token index from the vocabulary, getting the actual string representing the pad token from the field's `pad_token` attribute, which is `<pad>` by default.\n",
        "\n",
        "**Note:** we have switched models from the Vanilla RNN, we are now using the new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv48-KjNG7go"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Htz1XPG7gq"
      },
      "source": [
        "We'll print out the number of parameters in our model. \n",
        "\n",
        "Notice how we have almost twice as many parameters as before!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60hyUHixG7gr",
        "outputId": "c3238e7e-9c16-426e-a385-b788b8c67ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,810,857 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGtmGTEIG7g4"
      },
      "source": [
        "Now to training the model.\n",
        "\n",
        "We'll continue using the optimizer  `Adam`. `Adam` adapts the learning rate for each parameter, giving parameters that are updated more frequently lower learning rates and parameters that are updated infrequently higher learning rates. More information about `Adam` (and other optimizers) can be found [here](http://ruder.io/optimizing-gradient-descent/index.html).\n",
        "We define the criterion and place the model and criterion on the GPU (if available).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCD6WlWhG7g5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxXhWmlHG7gy"
      },
      "source": [
        "The final addition is copying the pre-trained word embeddings we loaded earlier into the `embedding` layer of our model. We replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n",
        "\n",
        "**Note**: this should always be done on the `weight.data` and not the `weight`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daNJCH9qG7gy"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjtzmHoRG7g4"
      },
      "source": [
        "We can now see the first two rows of the embedding weights matrix have been set to zeros. As we passed the index of the pad token to the `padding_idx` of the embedding layer it will remain zeros throughout training, however the `<unk>` token embedding will be learned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVZ62GnhG7g4"
      },
      "source": [
        "###5.2 Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clg5YzTqG7hA"
      },
      "source": [
        "We define a function for training our model. \n",
        "\n",
        "The function uses the same train and evaluate utility functions as before.\n",
        "**Note**: as we are now using dropout, we must remember to use `model.train()` to ensure the dropout is \"turned on\" while training and `model.eval()` to turn dropout off while evaluating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI9wXSs9G7hI"
      },
      "source": [
        "Finally, we train our model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0GIX0NLG7hI",
        "outputId": "b0fce46b-df1b-4c8f-f554-6312cfdbc1cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 43s\n",
            "\tTrain Loss: 0.640 | Train Acc: 62.67%\n",
            "\t Val. Loss: 0.529 |  Val. Acc: 75.69%\n",
            "Epoch: 02 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.640 | Train Acc: 62.45%\n",
            "\t Val. Loss: 0.498 |  Val. Acc: 76.48%\n",
            "Epoch: 03 | Epoch Time: 0m 44s\n",
            "\tTrain Loss: 0.531 | Train Acc: 73.15%\n",
            "\t Val. Loss: 0.403 |  Val. Acc: 82.58%\n",
            "Epoch: 04 | Epoch Time: 0m 44s\n",
            "\tTrain Loss: 0.359 | Train Acc: 84.50%\n",
            "\t Val. Loss: 0.314 |  Val. Acc: 86.65%\n",
            "Epoch: 05 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.307 | Train Acc: 87.40%\n",
            "\t Val. Loss: 0.277 |  Val. Acc: 88.81%\n",
            "Epoch: 06 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.265 | Train Acc: 89.28%\n",
            "\t Val. Loss: 0.297 |  Val. Acc: 87.97%\n",
            "Epoch: 07 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.234 | Train Acc: 90.99%\n",
            "\t Val. Loss: 0.263 |  Val. Acc: 89.22%\n",
            "Epoch: 08 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.213 | Train Acc: 91.93%\n",
            "\t Val. Loss: 0.261 |  Val. Acc: 89.60%\n",
            "Epoch: 09 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.187 | Train Acc: 92.98%\n",
            "\t Val. Loss: 0.262 |  Val. Acc: 90.90%\n",
            "Epoch: 10 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.169 | Train Acc: 93.62%\n",
            "\t Val. Loss: 0.260 |  Val. Acc: 90.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viBFY7I3BtEZ"
      },
      "source": [
        "###5.3 Test the Model\n",
        "We will first assess the accuracy, then we will assess sentiment from the quotes used in part 4.4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNBQ7LdG7hL",
        "outputId": "20fea28e-b0fc-4e36-c23d-4ba128c82c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.289 | Test Acc: 89.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jh1jvV6G7hN"
      },
      "source": [
        "#### User Input\n",
        "\n",
        "We can now use our model to predict the sentiment of any sentence we give it just as before, using the `predict_sentiment` function.\n",
        "\n",
        "We are expecting reviews with a negative sentiment to return a value close to 0 and positive reviews to return a value close to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sKjYrxRG7hP"
      },
      "source": [
        "An example negative review for Inception, Rotten Tomatoes Rating = 2. And the Angry Birds 2 Movie.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMAy_bllG7hP",
        "outputId": "8f58f667-ee84-428b-8c75-14a3a34fdf85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"I will pretend I loved it and worship it like all the the smartest people and didn't get kinda lost half way and stopped watching like 40 minutes before the end cause I was utterly uninterested in how it would end.\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10907997936010361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kly5O48IOn0L",
        "outputId": "498227d9-6f36-4b4d-bf7c-db03c8d45f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"Children will sit through it happily enough, but they deserve better, don't they?\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0964517816901207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZy1tE-cNYuS"
      },
      "source": [
        "Rotten Tomatoes rating 3 and 3.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zIgQx0sNQHc",
        "outputId": "13a84d42-d2b4-460c-d481-168efef0a597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model,\"Invention runs lower once we're on those snowy slopes, and the hard narrative punch keeps disintegrating into a floating cloud of pixels.\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8352929949760437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhUvZJZwLLQ6",
        "outputId": "9412fd34-951b-4cdb-b8d4-4f80ca9ba815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"The idea of the show, and the acting are amazing, but even as a lover of violence, some of the scenes involving animals and even some scenes involving people just felt.... baseless\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18680378794670105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofc-P36CKu-y",
        "outputId": "91493620-3a3c-4170-e50b-2683a287bfbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"Inception isn't a dud but nor is it a masterpiece. It's like a very ambitious, overlong potboiler: visually beautiful, ingenious in parts and dragging in others.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9655977487564087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUsiCyL-G7hR"
      },
      "source": [
        "An example positive review..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4gCUwy8G7hR",
        "outputId": "43469189-b640-4555-d20f-0d9df207f4b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"A spectacular fantasy thriller based on Nolan's own original screenplay, Inception is the smartest CGI head-trip since The Matrix.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9953552484512329"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j_1zSQrG7ha"
      },
      "source": [
        "##6 Questions to Answer for Homework\n",
        "\n",
        "We've now built a decent sentiment analysis model for movie reviews! \n",
        "\n",
        "**Homework Questions**\n",
        "1. Run the single layer Vanilla RNN and LSTM models in section 4. Write down the number of parameters and plot the training and validation errors over the epochs. Note the time per iteration and the final accuracy. Comment on the results that you got with the different test review examples.\n",
        "\n",
        "2. Compare the computational cost for LSTMs and regular RNNs for a given hidden dimension. Pay special attention to the training and inference cost.\n",
        "\n",
        "3. What happens to the gradient in an RNN and an LSTM if you backpropagate through a long sequence? Show the form of the derivative for both cases.\n",
        "\n",
        "4. Run the more complex models in section 5 for at least two different options.  You can select 2 or more layers for a deep RNN and can select if you want to add in the bidirectional option. Write down the number of parameters and plot the training and validation errors over the epochs for the cases. You may need to add in extra training epochs as you create deeper networks. Note the time per iteration and the final accuracy. Comment on the results that you got with the different test review examples.\n",
        "\n",
        "5. In a bidirectional RNN, if the different directions use a different number of hidden units, how will the shape of  $ùêá_ùë°$ change?\n",
        "\n",
        "6. If someone asked you to repurpose your system to analyse product reviews on Amazon.com. Would you be able to use the trained system directly? Would you want to combine sources from different types of reviews when modeling text? Is this a good idea? What could go wrong?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSLL9BIEDIAh"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Vanilla_LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        #self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        # LSTM layer\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #output, hidden = self.rnn(embedded)\n",
        "\n",
        "        # Output for LSTM\n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwCmf01NckRl"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = Vanilla_LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3XCNudQc8Kg"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pONOCScdAD1",
        "outputId": "9b638c0f-10b4-45e7-cbed-c6fb8b516bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.7922, -0.1901, -0.0676,  ...,  1.0146,  0.2398,  0.0675],\n",
              "        [ 0.4161, -0.1577, -0.0735,  ...,  0.3023,  0.2679,  0.6584],\n",
              "        [ 0.9501, -0.7701,  0.1537,  ..., -2.0229,  0.4822, -1.0561]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD6I0ZeteKZM",
        "outputId": "29a57e36-bd39-4251-c380-183ada33f2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.7922, -0.1901, -0.0676,  ...,  1.0146,  0.2398,  0.0675],\n",
            "        [ 0.4161, -0.1577, -0.0735,  ...,  0.3023,  0.2679,  0.6584],\n",
            "        [ 0.9501, -0.7701,  0.1537,  ..., -2.0229,  0.4822, -1.0561]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxbXpMrWgpXc",
        "outputId": "b7185b7b-df8d-4290-910a-76ee79a806b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,867,049 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dchW-8GXfNUo",
        "outputId": "47a46759-1597-4c63-b754-31f0e16295c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.667 | Train Acc: 61.42%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 66.75%\n",
            "Epoch: 02 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.631 | Train Acc: 66.02%\n",
            "\t Val. Loss: 0.517 |  Val. Acc: 78.20%\n",
            "Epoch: 03 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.514 | Train Acc: 76.84%\n",
            "\t Val. Loss: 0.457 |  Val. Acc: 81.41%\n",
            "Epoch: 04 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.415 | Train Acc: 81.40%\n",
            "\t Val. Loss: 0.330 |  Val. Acc: 86.10%\n",
            "Epoch: 05 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.239 | Train Acc: 90.97%\n",
            "\t Val. Loss: 0.323 |  Val. Acc: 86.79%\n",
            "Epoch: 06 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.165 | Train Acc: 94.48%\n",
            "\t Val. Loss: 0.316 |  Val. Acc: 87.64%\n",
            "Epoch: 07 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.119 | Train Acc: 96.35%\n",
            "\t Val. Loss: 0.350 |  Val. Acc: 88.27%\n",
            "Epoch: 08 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.075 | Train Acc: 97.93%\n",
            "\t Val. Loss: 0.381 |  Val. Acc: 88.17%\n",
            "Epoch: 09 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.048 | Train Acc: 98.87%\n",
            "\t Val. Loss: 0.383 |  Val. Acc: 87.86%\n",
            "Epoch: 10 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.035 | Train Acc: 99.24%\n",
            "\t Val. Loss: 0.456 |  Val. Acc: 87.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmOwO7B4ifgR",
        "outputId": "74c1411a-b931-4427-9d6e-c898ba0e92ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.339 | Test Acc: 86.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtHmFhhLzk_L"
      },
      "source": [
        "###6.1 Run the single layer Vanilla RNN and LSTM models in section 4. Write down the number of parameters and plot the training and validation errors over the epochs. Note the time per iteration and the final accuracy. Comment on the results that you got with the different test review examples.\n",
        "\n",
        "Note the time per iteration and the final accuracy. \n",
        "\n",
        "Comment on the results that you got with the different test review examples.\n",
        "\n",
        "\n",
        "> **RNN:**\n",
        "\n",
        "\n",
        "The model has 2,592,105 trainable parameters\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0\n",
        "\n",
        "Epoch: 10 | Epoch Time: 0m 5s\n",
        "\tTrain Loss: 0.673 | Train Acc: 56.69%\n",
        "\t Val. Loss: 0.692 |  Val. Acc: 51.09%\n",
        "\n",
        "It takes around 5 s per iteration.\n",
        "\n",
        "\n",
        "Test Loss: 0.665 | Test Acc: 59.92%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> **LSTM:**\n",
        "\n",
        "\n",
        "The model has 2,867,049 trainable parameters\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0\n",
        "\n",
        "\n",
        "Epoch: 10 | Epoch Time: 0m 10s\n",
        "\tTrain Loss: 0.035 | Train Acc: 99.24%\n",
        "\t Val. Loss: 0.456 |  Val. Acc: 87.66%\n",
        "\n",
        "It takes around 9 s per iteration.\n",
        "\n",
        "Test Loss: 0.339 | Test Acc: 86.69%\n",
        "\n",
        "\n",
        "\n",
        "> **Results**\n",
        "\n",
        "RNN takes less time but LSTM have much better accuracy for both of training and testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crZvgADF2U0u"
      },
      "source": [
        "###6.2 Compare the computational cost for LSTMs and regular RNNs for a given hidden dimension. Pay special attention to the training and inference cost.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> **RNN:**\n",
        "\n",
        "\n",
        "The model has 2,592,105 trainable parameters\n",
        "\n",
        "It takes around 5s.\n",
        "\n",
        "\n",
        "\n",
        "> **LSTM:**\n",
        "\n",
        "\n",
        "The model has 2,867,049 trainable parameters\n",
        "\n",
        "It takes around 9s.\n",
        "\n",
        "Moreover, the computational complexity is O(W) for LSTMs and RNNs. RNN: W < LSTM: W, so LSTM takes twice more than RNN but the trainibale parameters of LSTM is bigger than RNN's."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3wvSUji75j1"
      },
      "source": [
        "###6.3 What happens to the gradient in an RNN and an LSTM if you backpropagate through a long sequence? Show the form of the derivative for both cases.\n",
        "\n",
        "\n",
        "There would be no big difference for the form of the derivative but it would be very complicated to calculate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4wJ7Uem79Fg"
      },
      "source": [
        "###6.4 Run the more complex models in section 5 for at least two different options.  You can select 2 or more layers for a deep RNN and can select if you want to add in the bidirectional option. Write down the number of parameters and plot the training and validation errors over the epochs for the cases. You may need to add in extra training epochs as you create deeper networks. Note the time per iteration and the final accuracy. Comment on the results that you got with the different test review examples.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> **The given one:**\n",
        "\n",
        "\n",
        "The model has 4,810,857 trainable parameters\n",
        "\n",
        "Epoch: 10 | Epoch Time: 0m 45s\n",
        "\tTrain Loss: 0.169 | Train Acc: 93.62%\n",
        "\t Val. Loss: 0.260 |  Val. Acc: 90.37%\n",
        "\n",
        "Test Loss: 0.289 | Test Acc: 89.04%\n",
        "\n",
        "It takes around 45s per iteration.\n",
        "\n",
        "\n",
        "\n",
        "> **With N_Layer = 3**\n",
        "\n",
        "\n",
        "The model has 6,387,817 trainable parameters\n",
        "\n",
        "\n",
        "Epoch: 10 | Epoch Time: 1m 16s\n",
        "\tTrain Loss: 0.132 | Train Acc: 95.28%\n",
        "\t Val. Loss: 0.264 |  Val. Acc: 90.98%\n",
        "\n",
        "Test Loss: 0.273 | Test Acc: 89.06%\n",
        "\n",
        "\n",
        "It takes around 76s per iteration.\n",
        "\n",
        "\n",
        "> **With Bidirectional = False**\n",
        "\n",
        "\n",
        "The model has 3,393,641 trainable parameters\n",
        "\n",
        "Epoch: 10 | Epoch Time: 0m 20s\n",
        "\tTrain Loss: 0.118 | Train Acc: 95.64%\n",
        "\t Val. Loss: 0.338 |  Val. Acc: 89.95%\n",
        "\n",
        "Test Loss: 0.295 | Test Acc: 88.25%\n",
        "\n",
        "It takes around 20 s per iteration.\n",
        "\n",
        "\n",
        "> **Results**\n",
        "\n",
        "Without Bidirectional, it takes little shorter and little worse accuracy.\n",
        "\n",
        "With the larger number of layers, it takes little longer and gets little better accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiHtdw5xf0_O"
      },
      "source": [
        "####6.4.1\n",
        "With N_Later = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MF0DOdvJHLQ"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 3\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGaEaQBBJKes",
        "outputId": "0d98d8cb-9532-42fd-aafe-ee47648bcc1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 6,387,817 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VuDFwq5JNAH"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8roLqQwJPuo"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgQ1umHNJSBO",
        "outputId": "b245514e-5050-4710-aa6c-a4edc31dc035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.666 | Train Acc: 58.97%\n",
            "\t Val. Loss: 0.678 |  Val. Acc: 62.66%\n",
            "Epoch: 02 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.543 | Train Acc: 73.15%\n",
            "\t Val. Loss: 0.405 |  Val. Acc: 83.13%\n",
            "Epoch: 03 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.389 | Train Acc: 83.19%\n",
            "\t Val. Loss: 0.298 |  Val. Acc: 87.84%\n",
            "Epoch: 04 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.312 | Train Acc: 87.13%\n",
            "\t Val. Loss: 0.266 |  Val. Acc: 89.20%\n",
            "Epoch: 05 | Epoch Time: 1m 17s\n",
            "\tTrain Loss: 0.253 | Train Acc: 90.09%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 89.36%\n",
            "Epoch: 06 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.218 | Train Acc: 91.61%\n",
            "\t Val. Loss: 0.250 |  Val. Acc: 90.05%\n",
            "Epoch: 07 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.194 | Train Acc: 92.67%\n",
            "\t Val. Loss: 0.312 |  Val. Acc: 89.52%\n",
            "Epoch: 08 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.175 | Train Acc: 93.49%\n",
            "\t Val. Loss: 0.253 |  Val. Acc: 90.59%\n",
            "Epoch: 09 | Epoch Time: 1m 17s\n",
            "\tTrain Loss: 0.155 | Train Acc: 94.37%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 90.17%\n",
            "Epoch: 10 | Epoch Time: 1m 16s\n",
            "\tTrain Loss: 0.132 | Train Acc: 95.28%\n",
            "\t Val. Loss: 0.264 |  Val. Acc: 90.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ODnxH-sJUll",
        "outputId": "b5b95c70-b60d-47b4-9a6a-5b5c67a6f11f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.273 | Test Acc: 89.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDnCuagufdWy"
      },
      "source": [
        "####6.4.2\n",
        "Bidirectional = false"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM0S3JuEli4U"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = False\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq4b-wmAllfH",
        "outputId": "345b20e2-5ee0-4fcb-84ec-11946ccb4b50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,393,641 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpRjVd8zlo9I"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT3EGKwclsR0"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3hutCO0lvFg",
        "outputId": "386b0a93-a137-4046-dd2f-22c501fcb420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.450 | Train Acc: 80.20%\n",
            "\t Val. Loss: 0.400 |  Val. Acc: 83.29%\n",
            "Epoch: 02 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.385 | Train Acc: 83.73%\n",
            "\t Val. Loss: 0.339 |  Val. Acc: 86.41%\n",
            "Epoch: 03 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.313 | Train Acc: 87.62%\n",
            "\t Val. Loss: 0.327 |  Val. Acc: 87.28%\n",
            "Epoch: 04 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.252 | Train Acc: 90.33%\n",
            "\t Val. Loss: 0.363 |  Val. Acc: 87.06%\n",
            "Epoch: 05 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.218 | Train Acc: 91.29%\n",
            "\t Val. Loss: 0.280 |  Val. Acc: 89.12%\n",
            "Epoch: 06 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.193 | Train Acc: 92.59%\n",
            "\t Val. Loss: 0.290 |  Val. Acc: 88.45%\n",
            "Epoch: 07 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.177 | Train Acc: 93.61%\n",
            "\t Val. Loss: 0.304 |  Val. Acc: 89.72%\n",
            "Epoch: 08 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.153 | Train Acc: 94.09%\n",
            "\t Val. Loss: 0.297 |  Val. Acc: 89.85%\n",
            "Epoch: 09 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.132 | Train Acc: 95.19%\n",
            "\t Val. Loss: 0.312 |  Val. Acc: 89.66%\n",
            "Epoch: 10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.118 | Train Acc: 95.64%\n",
            "\t Val. Loss: 0.338 |  Val. Acc: 89.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwrc8nVmlzBA",
        "outputId": "a0fd4077-4ca6-47c7-c78f-8c122fac8297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.295 | Test Acc: 88.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMlO5b3emSHv"
      },
      "source": [
        "###6.5 In a bidirectional RNN, if the different directions use a different number of hidden units, how will the shape of  $ùêá_ùë°$ change?\n",
        "\n",
        "\n",
        "It is avaialble to use different numbers of hidden units for the different directions. However becare ful with the shape of forward and backward hidden state. The final one will be the combined one of the forward and backward hidden state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYI0-ScRmVRj"
      },
      "source": [
        "###6.6 If someone asked you to repurpose your system to analyse product reviews on Amazon.com. Would you be able to use the trained system directly? Would you want to combine sources from different types of reviews when modeling text? Is this a good idea? What could go wrong?\n",
        "\n",
        "\n",
        "I think it would be able to use the trained system directly. However, for better accuracy, it need to be retrained. This is about movies, so if there would be reviews about products, it would be better. \n",
        "\n",
        "If you use other reviews from other field, it could go wrong. For example, people use different words for different situation."
      ]
    }
  ]
}